{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import copy\n",
    "import re\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial.distance import jensenshannon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X-CRISP-MSE', 'X-CRISP-KLD', 'inDelphi', 'Lindel', 'FORECasT'] loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MIN_NUM_READS = 100\n",
    "\n",
    "XCRISP_PREDICTIONS_F = \"/Users/colm/repos/output/local/model_predictions/OurModel/model_1_v4_RS_1_{}.pkl\"\n",
    "XCRISP_KLD_PREDICTIONS_F = \"/Users/colm/repos/output/local/model_predictions/OurModel/model_v4_kld_{}.pkl\"\n",
    "LINDEL_PREDICTIONS_F = \"/Users/colm/repos/output/local/model_predictions/Lindel/predictions_{}x_{}.pkl\"\n",
    "FORECasT_PREDICTIONS_F = \"/Users/colm/repos/output/local/model_predictions/FORECasT/predictions_{}x_{}.pkl\"\n",
    "INDELPHI_PREDICTIONS_F = \"/Users/colm/repos/output/local/model_predictions/inDelphi/{}_predictions.pkl\"\n",
    "# TEST_FILES = [\"test\", \"0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1\", \"052218-U2OS-+-LibA-postCas9-rep1_transfertest\", \"0226-PRLmESC-Lib1-Cas9_transfertest\", \"TREX_A_test\", \"HAP1_test\"]\n",
    "TEST_FILES = [\"test\", \"0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1\"]\n",
    "BASELINE_TEST_FILES = [\"test\", \"0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1\"]\n",
    "data = {}\n",
    "\n",
    "for i, t in enumerate(TEST_FILES):\n",
    "    data[t] = {}\n",
    "    data[t][\"X-CRISP-MSE\"] = pkl.load(open(XCRISP_PREDICTIONS_F.format(t), 'rb'))\n",
    "    data[t][\"X-CRISP-KLD\"] = pkl.load(open(XCRISP_KLD_PREDICTIONS_F.format(t), 'rb'))\n",
    "    data[t][\"inDelphi\"] = pkl.load(open(INDELPHI_PREDICTIONS_F.format(t), 'rb'))\n",
    "    data[t][\"Lindel\"] = pkl.load(open(LINDEL_PREDICTIONS_F.format(MIN_NUM_READS, t), 'rb'))\n",
    "    data[t][\"FORECasT\"] = pkl.load(open(FORECasT_PREDICTIONS_F.format(MIN_NUM_READS, t), 'rb'))\n",
    "\n",
    "    # need to remove psuedocounts that were added to profiles in preparation for training\n",
    "    for target_site in data[t][\"FORECasT\"].keys():\n",
    "        data[t][\"FORECasT\"][target_site][\"actual\"] = np.array(data[t][\"FORECasT\"][target_site][\"actual\"]) - 0.5\n",
    "\n",
    "models = list(data[t].keys())\n",
    "print(models, \"loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "052218-U2OS-+-LibA-postCas9-rep1_transfertest X-CRISP-MSE 0_0_0_0_AAATATCTTTAACCTAAAAC\n"
     ]
    }
   ],
   "source": [
    "t = \"052218-U2OS-+-LibA-postCas9-rep1_transfertest\"\n",
    "method = \"X-CRISP-MSE\"\n",
    "target_site = \"0_0_0_0_AAATATCTTTAACCTAAAAC\"\n",
    "print(t, method, target_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test X-CRISP-MSE Oligo_43170 434\n",
      "test X-CRISP-MSE Oligo_43170 434\n",
      "test X-CRISP-MSE Oligo_43170 434\n",
      "test X-CRISP-MSE Oligo_43170 434\n",
      "test X-CRISP-KLD Oligo_43170 434\n",
      "test X-CRISP-KLD Oligo_43170 434\n",
      "test X-CRISP-KLD Oligo_43170 434\n",
      "test X-CRISP-KLD Oligo_43170 434\n",
      "test inDelphi Oligo_43170 107\n",
      "test inDelphi Oligo_43170 107\n",
      "test inDelphi Oligo_43170 107\n",
      "test inDelphi Oligo_43170 107\n",
      "test Lindel Oligo_43170 557\n",
      "test Lindel Oligo_43170 557\n",
      "test Lindel Oligo_43170 557\n",
      "test Lindel Oligo_43170 557\n",
      "test FORECasT Oligo_43170 398\n",
      "test FORECasT Oligo_43170 398\n",
      "test FORECasT Oligo_43170 398\n",
      "test FORECasT Oligo_43170 398\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 X-CRISP-MSE 0_0_0_0_CTTTCACTTTATAGATTTAT 393\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 X-CRISP-MSE 0_0_0_0_CTTTCACTTTATAGATTTAT 393\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 X-CRISP-MSE 0_0_0_0_CTTTCACTTTATAGATTTAT 393\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 X-CRISP-MSE 0_0_0_0_CTTTCACTTTATAGATTTAT 393\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 X-CRISP-KLD 0_0_0_0_CTTTCACTTTATAGATTTAT 393\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 X-CRISP-KLD 0_0_0_0_CTTTCACTTTATAGATTTAT 393\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 X-CRISP-KLD 0_0_0_0_CTTTCACTTTATAGATTTAT 393\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 X-CRISP-KLD 0_0_0_0_CTTTCACTTTATAGATTTAT 393\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 inDelphi 0_0_0_0_CTTTCACTTTATAGATTTAT 122\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 inDelphi 0_0_0_0_CTTTCACTTTATAGATTTAT 122\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 inDelphi 0_0_0_0_CTTTCACTTTATAGATTTAT 122\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 inDelphi 0_0_0_0_CTTTCACTTTATAGATTTAT 122\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 Lindel 0_0_0_0_CTTTCACTTTATAGATTTAT 557\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 Lindel 0_0_0_0_CTTTCACTTTATAGATTTAT 557\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 Lindel 0_0_0_0_CTTTCACTTTATAGATTTAT 557\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 Lindel 0_0_0_0_CTTTCACTTTATAGATTTAT 557\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 FORECasT 0_0_0_0_CTTTCACTTTATAGATTTAT 352\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 FORECasT 0_0_0_0_CTTTCACTTTATAGATTTAT 352\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 FORECasT 0_0_0_0_CTTTCACTTTATAGATTTAT 352\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 FORECasT 0_0_0_0_CTTTCACTTTATAGATTTAT 352\n"
     ]
    }
   ],
   "source": [
    "for t in TEST_FILES:\n",
    "    for m in models:\n",
    "        target_site = list(data[t][m].keys())[0]\n",
    "        for k in data[t][m][target_site].keys():\n",
    "            print(t, m, target_site, len(data[t][m][target_site][k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test X-CRISP-MSE 3954\n",
      "test X-CRISP-KLD 3954\n",
      "test inDelphi 3739\n",
      "test Lindel 3939\n",
      "test FORECasT 3939\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 X-CRISP-MSE 1961\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 X-CRISP-KLD 1961\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 inDelphi 1957\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 Lindel 1961\n",
      "0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1 FORECasT 1961\n",
      "There are 3738 oligos common to test\n",
      "There are 1957 oligos common to 0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1\n"
     ]
    }
   ],
   "source": [
    "for t in TEST_FILES:\n",
    "    for e in data[t]:\n",
    "        print(t, e, len(data[t][e].keys()))\n",
    "\n",
    "# collect targets common to all experiments\n",
    "\n",
    "from functools import reduce\n",
    "common_oligos = {}\n",
    "\n",
    "\n",
    "for t in TEST_FILES:\n",
    "    ts = []\n",
    "    ts.append(list(data[t][\"Lindel\"].keys()))\n",
    "    ts.append(list(data[t][\"inDelphi\"].keys()))\n",
    "    ts.append(list(data[t][\"FORECasT\"].keys()))\n",
    "    common_oligos[t] = reduce(np.intersect1d, ts)\n",
    "    print(f\"There are {len(common_oligos[t])} oligos common to {t}\")\n",
    "\n",
    "# reformat FORECasT indels\n",
    "def FC_indel_to_our(fc):\n",
    "    parts = fc.split(\"_\")\n",
    "    t = parts[0][0] # type I or D \n",
    "    l = int(parts[0][1:]) # size\n",
    "    p = int(parts[1].split(\"R\")[1]) # start\n",
    "    if t == \"D\":\n",
    "        return \"{}+{}\".format(p-l, l)\n",
    "    else:\n",
    "        # return \"I{}\".format(l)\n",
    "        return fc\n",
    "\n",
    "def inDelphi_to_our(ind):\n",
    "    if ind[-1] in \"ACGT\":\n",
    "        return \"1+\" + ind[-1]\n",
    "    if ind.isnumeric():\n",
    "        return \"DL\" + ind \n",
    "    return ind\n",
    "\n",
    "for t in TEST_FILES:\n",
    "    for o in common_oligos[t]:\n",
    "        if \"FORECasT\" in data[t]:\n",
    "            data[t][\"FORECasT\"][o][\"indels\"] = [FC_indel_to_our(i) for i in data[t][\"FORECasT\"][o][\"indels\"]]\n",
    "        if \"inDelphi\" in data[t]:\n",
    "            data[t][\"inDelphi\"][o][\"indels\"] = [inDelphi_to_our(i) for i in data[t][\"inDelphi\"][o][\"indels\"]]\n",
    "\n",
    "# np.seterr(all='raise')\n",
    "file_mapping = {\n",
    "    \"test\": \"FORECasT WT\",\n",
    "    \"0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1\": \"inDelphi WT\",\n",
    "    \"WT\": \"LUMC WT\",\n",
    "    \"0226-PRLmESC-Lib1-Cas9_transfertest\": \"inDelphi NHEJ-deficient\",\n",
    "    \"052218-U2OS-+-LibA-postCas9-rep1_transfertest\": \"inDelphi USO2 WT\",\n",
    "    \"HAP1_test\": \"FORECasT HAP1\",\n",
    "    \"TREX_A_test\": \"FORECasT TREX\",\n",
    "    \"2A_TREX_A_test\": \"2A_FORECasT TREX\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ins mappings to FORECasT output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped output to FORECasT\n",
      "{'I1_L-1C1R1': '1+A', 'I1_L-2C1R0': '1+T', 'I2_L-1C1R1': '2+TA', 'I2_L-1C2R2': '2+AG', 'I2_L-2C1R0': '2+CT', 'I2_L-2C2R1': '2+TA', 'I2_L-3C2R0': '2+CT', 'I1_L-1R0': ['1+C', '1+G'], 'I2_L-1R0': ['2+AA', '2+AC', '2+AT', '2+CA', '2+CC', '2+CG', '2+GA', '2+GC', '2+GG', '2+GT', '2+TC', '2+TG', '2+TT']}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sys.path.append(\"../modelling\")\n",
    "from src.data.data_loader import get_details_from_fasta\n",
    "\n",
    "# test over a common set of indels per target site\n",
    "def generate_1_and_2_bp_insertions():\n",
    "    nucs = [\"A\", \"C\", \"G\", \"T\"]\n",
    "    onebps = []\n",
    "    twobps = []\n",
    "    for n1 in nucs:\n",
    "        onebps.append(\"1+\" + n1)\n",
    "        for n2 in nucs:\n",
    "            twobps.append(\"2+\" + n1 + n2)\n",
    "    return onebps + twobps\n",
    "\n",
    "common_insertions = generate_1_and_2_bp_insertions()\n",
    "\n",
    "fasta_files = [\"../../src/data/FORECasT/test.fasta\", \"../../src/data/inDelphi/LibA.fasta\"]\n",
    "guides = {}\n",
    "\n",
    "for ff in fasta_files:\n",
    "    guides.update(get_details_from_fasta(ff))\n",
    "\n",
    "ins_mapping = {}\n",
    "t = \"test\"\n",
    "for t in TEST_FILES:\n",
    "    ins_mapping[t] = {}\n",
    "    for o in common_oligos[t]:\n",
    "        g = guides[o]\n",
    "        cutsite = g[\"PAM Index\"] - 3\n",
    "        ins_mapping[t][o] = {}\n",
    "        FORECasT_insertions = [i for i in data[t][\"FORECasT\"][o][\"indels\"] if \"I\" in i]\n",
    "        FORECasT_rep_insertions = [i for i in FORECasT_insertions if \"C\" in i]\n",
    "        FORECasT_norep_insertions = [i for i in FORECasT_insertions if \"C\" not in i]\n",
    "        if len(FORECasT_norep_insertions) not in [1, 2]: print(\"wtf\")\n",
    "        for i in FORECasT_rep_insertions:\n",
    "            _, I, _, L, C, R = re.split(\"I|_|L|C|R\", i)\n",
    "            rep_nuc = g[\"TargetSequence\"][cutsite + int(R) -int(I):cutsite + int(R)]\n",
    "            ins_mapping[t][o][i] = \"{}+{}\".format(int(I), rep_nuc)\n",
    "        for i in FORECasT_norep_insertions:\n",
    "            if i[1] == \"1\":\n",
    "                ins_mapping[t][o][i] = list(np.setdiff1d([c for c in common_insertions if \"1\" in c], list(ins_mapping[t][o].values()))) \n",
    "            if i[1] == \"2\":\n",
    "                ins_mapping[t][o][i] = list(np.setdiff1d([c for c in common_insertions if \"2\" in c], [c for c in list(ins_mapping[t][o].values()) if \"2\" in c])) \n",
    "print(\"mapped output to FORECasT\")\n",
    "print(ins_mapping[t][o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed mapping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1+A': 'I1_L-1C1R1',\n",
       " '1+T': 'I1_L-2C1R0',\n",
       " '2+TA': 'I2_L-2C2R1',\n",
       " '2+AG': 'I2_L-1C2R2',\n",
       " '2+CT': 'I2_L-3C2R0',\n",
       " '1+C': 'I1_L-1R0',\n",
       " '1+G': 'I1_L-1R0',\n",
       " '2+AA': 'I2_L-1R0',\n",
       " '2+AC': 'I2_L-1R0',\n",
       " '2+AT': 'I2_L-1R0',\n",
       " '2+CA': 'I2_L-1R0',\n",
       " '2+CC': 'I2_L-1R0',\n",
       " '2+CG': 'I2_L-1R0',\n",
       " '2+GA': 'I2_L-1R0',\n",
       " '2+GC': 'I2_L-1R0',\n",
       " '2+GG': 'I2_L-1R0',\n",
       " '2+GT': 'I2_L-1R0',\n",
       " '2+TC': 'I2_L-1R0',\n",
       " '2+TG': 'I2_L-1R0',\n",
       " '2+TT': 'I2_L-1R0'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_ins_mapping = {}\n",
    "for t in ins_mapping:\n",
    "    rev_ins_mapping[t] = {}\n",
    "    for o in ins_mapping[t]:\n",
    "        rev_ins_mapping[t][o] = {}\n",
    "        for i in ins_mapping[t][o]:\n",
    "            a = ins_mapping[t][o][i]\n",
    "            if isinstance(a, list):\n",
    "                for a2 in a:\n",
    "                    rev_ins_mapping[t][o][a2] = i\n",
    "            else:\n",
    "               rev_ins_mapping[t][o][a] = i\n",
    "print(\"Reversed mapping\")\n",
    "\n",
    "rev_ins_mapping[t][o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlate Observed and Predicted Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect predicted data into dataframe\n",
    "rows = []\n",
    "indices = []\n",
    "for t in TEST_FILES:\n",
    "    test_f = file_mapping[t]\n",
    "    for method in data[t].keys():\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"]) \n",
    "            predicted = data[t][method][target_site][\"predicted\"].astype(float) # Q\n",
    "            observed = data[t][method][target_site][\"actual\"].astype(float)/sum(data[t][method][target_site][\"actual\"].astype(float)) # P\n",
    "            indices.append((test_f, method, target_site))\n",
    "            correlation = np.corrcoef(predicted, observed)[0,1]\n",
    "            kl_divergence = entropy(observed, predicted)\n",
    "            js = jensenshannon(observed, predicted)\n",
    "            rows.append([correlation, kl_divergence, js])\n",
    "\n",
    "indices = pd.MultiIndex.from_tuples(indices, names=[\"Dataset\", \"Method\", \"Target Site\"])\n",
    "df = pd.DataFrame(rows, index=indices, columns=[\"Pearson's Correlation\", \"KL Divergence\", \"Jensen Shannon\"])\n",
    "inf_oligos = df[~np.isfinite(df[\"KL Divergence\"])].index.get_level_values(2)\n",
    "df = df[~df.index.get_level_values(2).isin(inf_oligos)]\n",
    "# df.to_csv(\"/Users/colm/repos/x-crisp/data/processed/Performance/overall.tsv\", sep=\"\\t\")\n",
    "# df.groupby([\"Dataset\", \"Method\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect predicted data into dataframe\n",
    "rows = []\n",
    "indices = []\n",
    "for t in TEST_FILES:\n",
    "    test_f = file_mapping[t]\n",
    "    common_indels = {}\n",
    "    for method in models:\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"])\n",
    "            mh = np.array(data[t][method][target_site][\"mh\"])\n",
    "            if (t not in BASELINE_TEST_FILES) and (\"X-CRISP\" in method):\n",
    "                mh = np.array(list(mh) + ([False] * 21))\n",
    "\n",
    "            if target_site in common_indels:\n",
    "                common_indels[target_site] = np.intersect1d(common_indels[target_site], indels[mh])\n",
    "            else:\n",
    "                common_indels[target_site] = indels[mh]\n",
    "    \n",
    "    for method in models:\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"])\n",
    "            # deletions = np.array([not is_insertion(x, method) for x in indels])\n",
    "            # mh = np.array(data[t][method][target_site][\"mh\"])\n",
    "            mh = np.isin(indels, common_indels[target_site])\n",
    "            predicted = data[t][method][target_site][\"predicted\"][mh].astype(float) # Q\n",
    "            observed = data[t][method][target_site][\"actual\"][mh].astype(float) # P\n",
    "\n",
    "            predicted = predicted/sum(predicted)\n",
    "            observed = observed/sum(observed)\n",
    "\n",
    "            # then calculate\n",
    "            indices.append((test_f, method, target_site))\n",
    "            correlation = np.corrcoef(predicted, observed)[0,1]\n",
    "            kl_divergence = entropy(observed, predicted)\n",
    "            js = jensenshannon(observed, predicted)\n",
    "            rows.append([correlation, kl_divergence, js])\n",
    "\n",
    "indices = pd.MultiIndex.from_tuples(indices, names=[\"Dataset\", \"Method\", \"Target Site\"])\n",
    "df = pd.DataFrame(rows, index=indices, columns=[\"Pearson's Correlation\", \"KL Divergence\", \"Jensen Shannon\"])\n",
    "inf_oligos = df[~np.isfinite(df[\"KL Divergence\"])].index.get_level_values(2)\n",
    "df = df[~df.index.get_level_values(2).isin(inf_oligos)]\n",
    "# df.to_csv(\"/Users/colm/repos/x-crisp/data/processed/Performance/mh.tsv\", sep=\"\\t\")\n",
    "# df.groupby([\"Dataset\", \"Method\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colm/anaconda3/envs/xcrisp/lib/python3.9/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/Users/colm/anaconda3/envs/xcrisp/lib/python3.9/site-packages/numpy/core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/Users/colm/anaconda3/envs/xcrisp/lib/python3.9/site-packages/numpy/lib/function_base.py:2846: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/Users/colm/anaconda3/envs/xcrisp/lib/python3.9/site-packages/numpy/lib/function_base.py:2705: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/Users/colm/anaconda3/envs/xcrisp/lib/python3.9/site-packages/numpy/lib/function_base.py:2705: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    }
   ],
   "source": [
    "def is_insertion(indel, method):\n",
    "    if method in [\"1NN\", \"KLD\", \"Lindel\", \"inDelphi\"] or \"transfer\" in method:\n",
    "        return indel in common_insertions or indel == \"3\" or indel == \"3+X\"\n",
    "    if method == \"FORECasT\":\n",
    "        return indel[0] == \"I\"\n",
    "\n",
    "# collect predicted data into dataframe\n",
    "rows = []\n",
    "indices = []\n",
    "for t in TEST_FILES:\n",
    "    test_f = file_mapping[t]\n",
    "    common_indels = {}\n",
    "    for method in models:\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"])\n",
    "            deletions = np.array([not is_insertion(x, method) for x in indels])\n",
    "            mhless = np.invert(np.array(data[t][method][target_site][\"mh\"]))\n",
    "            if (t not in BASELINE_TEST_FILES) and (\"X-CRISP\" in method):\n",
    "                mhless = np.array(list(mhless) + ([False] * 21))\n",
    "            mhless_deletions = deletions & mhless\n",
    "            if target_site in common_indels:\n",
    "                common_indels[target_site] = np.intersect1d(common_indels[target_site], indels[mhless_deletions])\n",
    "            else:\n",
    "                common_indels[target_site] = indels[mhless_deletions]\n",
    "\n",
    "\n",
    "    for method in models:\n",
    "        if method == \"inDelphi\": continue\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"])\n",
    "            mhless_deletions = np.isin(indels, common_indels[target_site])\n",
    "            predicted = data[t][method][target_site][\"predicted\"][mhless_deletions].astype(float) # Q\n",
    "            observed = data[t][method][target_site][\"actual\"][mhless_deletions].astype(float) # P\n",
    "\n",
    "            predicted = predicted/sum(predicted)\n",
    "            observed = observed/sum(observed)\n",
    "\n",
    "            # then calculate\n",
    "            indices.append((test_f, method, target_site))\n",
    "            correlation = np.corrcoef(predicted, observed)[0,1]\n",
    "            kl_divergence = entropy(observed, predicted)\n",
    "            js = jensenshannon(observed, predicted)\n",
    "            rows.append([correlation, kl_divergence, js])\n",
    "\n",
    "indices = pd.MultiIndex.from_tuples(indices, names=[\"Dataset\", \"Method\", \"Target Site\"])\n",
    "df = pd.DataFrame(rows, index=indices, columns=[\"Pearson's Correlation\", \"KL Divergence\", \"Jensen Shannon\"])\n",
    "inf_oligos = df[~np.isfinite(df[\"KL Divergence\"])].index.get_level_values(2)\n",
    "df = df[~df.index.get_level_values(2).isin(inf_oligos)]\n",
    "# df.to_csv(\"/Users/colm/repos/x-crisp/data/processed/Performance/mhless.tsv\", sep=\"\\t\")\n",
    "# df.groupby([\"Dataset\", \"Method\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': '../../src/data/FORECasT/test.fasta',\n",
       " '0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1': '../../src/data/inDelphi/LibA.fasta'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasta_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/n2td64g918lgvdh3qm2x3bhc0000gn/T/ipykernel_87817/1341803889.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  observed = observed/sum(observed)\n",
      "/Users/colm/anaconda3/envs/xcrisp/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/colm/anaconda3/envs/xcrisp/lib/python3.9/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "/var/folders/5x/n2td64g918lgvdh3qm2x3bhc0000gn/T/ipykernel_87817/1341803889.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  observed = observed/sum(observed)\n",
      "/Users/colm/anaconda3/envs/xcrisp/lib/python3.9/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/colm/anaconda3/envs/xcrisp/lib/python3.9/site-packages/numpy/lib/function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# copy takes about 14 seconds\n",
    "ins_data = copy.deepcopy(data)\n",
    "\n",
    "fasta_files = {\n",
    "    \"test\": \"../../src/data/FORECasT/test.fasta\",\n",
    "    \"0105-mESC-Lib1-Cas9-Tol2-BioRep2-techrep1\": \"../../src/data/inDelphi/LibA.fasta\"\n",
    "}\n",
    "\n",
    "guides = {}\n",
    "\n",
    "for ff in list(fasta_files.values()):\n",
    "    guides.update(get_details_from_fasta(ff))\n",
    "\n",
    "ins_mapping = {}\n",
    "t = \"test\"\n",
    "all_1bp_insertions = np.array([\"1+A\", \"1+C\", \"1+G\", \"1+T\"])\n",
    "for t in TEST_FILES:\n",
    "    ins_mapping[t] = {}\n",
    "    for o in common_oligos[t]:\n",
    "        g = guides[o]\n",
    "        cutsite = g[\"PAM Index\"] - 3\n",
    "        ins_mapping[t][o] = {}\n",
    "        FORECasT_insertions = [i for i in data[t][\"FORECasT\"][o][\"indels\"] if \"I1\" in i]\n",
    "        FORECasT_rep_insertions = [i for i in FORECasT_insertions if \"C\" in i]\n",
    "        FORECasT_norep_insertions = [i for i in FORECasT_insertions if \"C\" not in i]\n",
    "        if len(FORECasT_norep_insertions) != 1: print(\"wtf\")\n",
    "        for i in FORECasT_rep_insertions:\n",
    "            _, L, C, R = re.split(\"L|C|R\", i)\n",
    "            rep_nuc = g[\"TargetSequence\"][cutsite + int(R) -1]\n",
    "            ins_mapping[t][o][i] = \"1+{}\".format(rep_nuc)\n",
    "        for i in FORECasT_norep_insertions:\n",
    "            ins_mapping[t][o][i] = list(np.setdiff1d(all_1bp_insertions, list(ins_mapping[t][o].values()))) \n",
    "\n",
    "ins_mapping[t][o]\n",
    "\n",
    "def is_forecast_insertion(indel):\n",
    "        return indel[:2] == \"I1\"\n",
    "\n",
    "# collect predicted data into dataframe\n",
    "rows = []\n",
    "indices = []\n",
    "for t in TEST_FILES:\n",
    "    test_f = file_mapping[t]\n",
    "    common_indels = {}\n",
    "    # for method in [\"inDelphi\"]:\n",
    "    for method in [m for m in models if m != \"FORECasT\"]:\n",
    "        for target_site in common_oligos[t]:\n",
    "            new_predicted = []\n",
    "            new_observed = []\n",
    "            new_indels = []\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"])\n",
    "            predicted = pd.Series(list(data[t][method][target_site][\"predicted\"]), index=indels)\n",
    "            observed = pd.Series(list(data[t][method][target_site][\"actual\"]), index=indels)\n",
    "\n",
    "            predicted = predicted/sum(predicted)\n",
    "            observed = observed/sum(observed)\n",
    "\n",
    "            for i in ins_mapping[t][target_site]:\n",
    "                new_predicted.append(predicted.loc[ins_mapping[t][target_site][i]].sum())\n",
    "                new_observed.append(observed.loc[ins_mapping[t][target_site][i]].sum())\n",
    "                new_indels.append(i)\n",
    "\n",
    "            ins_data[t][method][target_site][\"indels\"] = np.array(new_indels)\n",
    "            ins_data[t][method][target_site][\"predicted\"] = np.array(new_predicted)\n",
    "            ins_data[t][method][target_site][\"actual\"] = np.array(new_observed)\n",
    "\n",
    "    for method in ins_data[t].keys():\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = ins_data[t][method][target_site][\"indels\"]\n",
    "            insertions = np.array([is_forecast_insertion(x) for x in indels])\n",
    "            predicted = ins_data[t][method][target_site][\"predicted\"][insertions].astype(float) # Q\n",
    "            observed = ins_data[t][method][target_site][\"actual\"][insertions].astype(float) # P\n",
    "\n",
    "            predicted = predicted/sum(predicted)\n",
    "            observed = observed/sum(observed)\n",
    "\n",
    "            # then calculate\n",
    "            indices.append((test_f, method, target_site))\n",
    "            correlation = np.corrcoef(predicted, observed)[0,1]\n",
    "            kl_divergence = entropy(observed, predicted)\n",
    "            js = jensenshannon(observed, predicted)\n",
    "\n",
    "            rows.append([correlation, kl_divergence, js])\n",
    "\n",
    "indices = pd.MultiIndex.from_tuples(indices, names=[\"Dataset\", \"Method\", \"Target Site\"])\n",
    "df = pd.DataFrame(rows, index=indices, columns=[\"Pearson's Correlation\", \"KL Divergence\", \"Jensen Shannon\"])\n",
    "# df.to_csv(\"/Users/colm/repos/x-crisp/data/processed/Performance/insertion.tsv\", sep=\"\\t\")\n",
    "# df.groupby([\"Dataset\", \"Method\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I1_L-1C1R1', 'I1_L-2C1R0', 'I1_L-1R0'], dtype='<U10')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = \"X-CRISP-MSE\"\n",
    "indels = ins_data[t][method][target_site][\"indels\"]\n",
    "insertions = np.array([is_forecast_insertion(x) for x in indels])\n",
    "# predicted = ins_data[t][method][target_site][\"predicted\"][insertions].astype(float) # Q\n",
    "# observed = ins_data[t][method][target_site][\"actual\"][insertions].astype(float) # P\n",
    "np.array(ins_data[t][method][target_site][\"indels\"])[insertions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished X-CRISP-MSE\n",
      "Finished X-CRISP-KLD\n",
      "Finished inDelphi\n",
      "Finished Lindel\n",
      "Finished FORECasT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colm/anaconda3/envs/xcrisp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  - f-score: both\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished X-CRISP-MSE\n",
      "Finished X-CRISP-KLD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colm/anaconda3/envs/xcrisp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  - f-score: both\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished inDelphi\n",
      "Finished Lindel\n",
      "Finished FORECasT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, matthews_corrcoef, recall_score, f1_score\n",
    "\n",
    "\n",
    "precisions = [.2, .3, .4, .5, .6, .7]\n",
    "precision_X_mcc = {}\n",
    "\n",
    "indices = []\n",
    "rows_prec = []\n",
    "rows_mcc = []\n",
    "rows_recall = []\n",
    "rows_f1_score = []\n",
    "for t in TEST_FILES:\n",
    "    test_f = file_mapping[t]\n",
    "    for method in data[t].keys():\n",
    "    # for method in [\"inDelphi\"]:\n",
    "        row_prec = []\n",
    "        row_mcc = []\n",
    "        row_recall = []\n",
    "        row_f1_score = []\n",
    "        for p in precisions:\n",
    "            precision_X_preds = []\n",
    "            precision_X_labels = []\n",
    "            for target_site in common_oligos[t]:\n",
    "                pred = np.array(data[t][method][target_site][\"predicted\"])\n",
    "                x = sum((pred/sum(pred)) > p) == 1\n",
    "                precision_X_preds.append(x)\n",
    "                obs = np.array(data[t][method][target_site][\"actual\"])\n",
    "                y = sum((obs/sum(obs)) > p) == 1\n",
    "                precision_X_labels.append(y)\n",
    "            row_prec.append(precision_score(precision_X_labels, precision_X_preds))\n",
    "            row_mcc.append(matthews_corrcoef(precision_X_labels, precision_X_preds))\n",
    "            row_recall.append(recall_score(precision_X_labels, precision_X_preds))\n",
    "            row_f1_score.append(recall_score(precision_X_labels, precision_X_preds))\n",
    "        print(\"Finished {}\".format(method))\n",
    "        rows_prec.append(row_prec)\n",
    "        rows_mcc.append(row_mcc) \n",
    "        rows_recall.append(row_recall)\n",
    "        rows_f1_score.append(row_f1_score)    \n",
    "        indices.append((test_f, method))\n",
    "        \n",
    "        \n",
    "  \n",
    "indices = pd.MultiIndex.from_tuples(indices, names=[\"Dataset\", \"Method\"])\n",
    "df_mcc = pd.DataFrame(rows_mcc, index=indices, columns=[\"Precision-{}\".format(p) for p in precisions])\n",
    "df_prec = pd.DataFrame(rows_prec, index=indices, columns=[\"Precision-{}\".format(p) for p in precisions])\n",
    "df_recall = pd.DataFrame(rows_recall, index=indices, columns=[\"Precision-{}\".format(p) for p in precisions])\n",
    "df_f1_score = pd.DataFrame(rows_f1_score, index=indices, columns=[\"Precision-{}\".format(p) for p in precisions])\n",
    "\n",
    "df_mcc.to_csv(\"/Users/colm/repos/x-crisp/data/processed/Performance/precision-X-mcc.tsv\", sep=\"\\t\")\n",
    "df_prec.to_csv(\"/Users/colm/repos/x-crisp/data/processed/Performance/precision-X-prec.tsv\", sep=\"\\t\")\n",
    "df_recall.to_csv(\"/Users/colm/repos/x-crisp/data/processed/Performance/precision-X-recall.tsv\", sep=\"\\t\")\n",
    "df_f1_score.to_csv(\"/Users/colm/repos/x-crisp/data/processed/Performance/precision-X-f1_score.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Statistics Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [82], line 78\u001b[0m\n\u001b[1;32m     76\u001b[0m indels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[t][method][target_site][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindels\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \n\u001b[1;32m     77\u001b[0m onebpdels \u001b[38;5;241m=\u001b[39m [is_1bp_deletion(x, method) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m indels]\n\u001b[0;32m---> 78\u001b[0m predonebpdelratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_site\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredicted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43monebpdels\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28msum\u001b[39m(data[t][method][target_site][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     79\u001b[0m predonebpdelfreq\u001b[38;5;241m.\u001b[39mappend(predonebpdelratio)\n\u001b[1;32m     80\u001b[0m obsonebpdelratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(data[t][method][target_site][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual\u001b[39m\u001b[38;5;124m\"\u001b[39m])[onebpdels])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28msum\u001b[39m(data[t][method][target_site][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# collect predicted data into dataframe\n",
    "def is_1bp_deletion(indel, method):\n",
    "    if method in [\"1NN\", \"KLD\", \"Lindel\", \"FORECasT\"]:\n",
    "        return indel.split(\"+\")[-1] == \"1\"\n",
    "    if method == \"inDelphi\":\n",
    "        return indel.split(\"+\")[-1] == \"1\" or indel == \"DL1\"\n",
    "\n",
    "def is_1bp_insertion(indel, method):\n",
    "    if method in [\"1NN\", \"KLD\", \"Lindel\", \"inDelphi\"]:\n",
    "        return indel in ['1+A', '1+C', '1+G', '1+T']\n",
    "    if method == 'FORECasT':\n",
    "        return indel[:2] == \"I1\"\n",
    "\n",
    "def is_insertion(indel, method):\n",
    "    if method in [\"1NN\", \"KLD\", \"Lindel\", \"inDelphi\"]:\n",
    "        return indel in common_insertions or indel == \"3\" or indel == \"3+X\"\n",
    "    if method == \"FORECasT\":\n",
    "        return indel[0] == \"I\"\n",
    "\n",
    "def is_frameshift(indel, method, t = \"any\"):\n",
    "    length = None\n",
    "    if method in [\"1NN\", \"KLD\", \"Lindel\"]:\n",
    "        if is_insertion(indel, method):\n",
    "            length = int(indel[0]) \n",
    "        else:\n",
    "            length = int(indel.split(\"+\")[-1]) \n",
    "    if method == \"inDelphi\":\n",
    "        if is_insertion(indel, method):\n",
    "            length = int(indel[0])\n",
    "        elif indel[:2] == \"DL\":\n",
    "            length = int(indel[2:])\n",
    "        else:\n",
    "            length = int(indel.split(\"+\")[-1]) \n",
    "    if method == \"FORECasT\":\n",
    "        if is_insertion(indel, method):\n",
    "            length = int(indel.split(\"_\")[0][1:])\n",
    "        else:\n",
    "            length = int(indel.split(\"+\")[-1]) \n",
    "        \n",
    "    allonebpframeshifts = np.array([1, 4, 7, 10, 13, 16, 19, 22, 25, 28])\n",
    "    alltwobpframeshifts = allonebpframeshifts + 1\n",
    "\n",
    "    if t == 1:\n",
    "        return length in allonebpframeshifts\n",
    "    elif t == 2:\n",
    "        return length in alltwobpframeshifts\n",
    "    else:\n",
    "        return length % 3 != 0\n",
    "\n",
    "rows = []\n",
    "indices = []\n",
    "for t in TEST_FILES:\n",
    "    test_f = file_mapping[t]\n",
    "    for method in data[t].keys():\n",
    "\n",
    "        # deletion frequency\n",
    "        # one basepair deletions\n",
    "        preddelfreq = []\n",
    "        obsdelfreq = []\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"]) \n",
    "            dels = [not is_insertion(x, method) for x in indels]\n",
    "            preddelratio = sum(np.array(data[t][method][target_site][\"predicted\"])[dels])/sum(data[t][method][target_site][\"predicted\"])\n",
    "            preddelfreq.append(preddelratio)\n",
    "            obsdelratio = sum(np.array(data[t][method][target_site][\"actual\"])[dels])/sum(data[t][method][target_site][\"actual\"])\n",
    "            obsdelfreq.append(obsdelratio)\n",
    "        delmse = mean_squared_error(preddelfreq, obsdelfreq)\n",
    "\n",
    "\n",
    "        # one basepair deletions\n",
    "        predonebpdelfreq = []\n",
    "        obsonebpdelfreq = []\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"]) \n",
    "            onebpdels = [is_1bp_deletion(x, method) for x in indels]\n",
    "            predonebpdelratio = sum(np.array(data[t][method][target_site][\"predicted\"])[onebpdels])/sum(data[t][method][target_site][\"predicted\"])\n",
    "            predonebpdelfreq.append(predonebpdelratio)\n",
    "            obsonebpdelratio = sum(np.array(data[t][method][target_site][\"actual\"])[onebpdels])/sum(data[t][method][target_site][\"actual\"])\n",
    "            obsonebpdelfreq.append(obsonebpdelratio)\n",
    "        onebpdelmse = mean_squared_error(predonebpdelfreq, obsonebpdelfreq)\n",
    "\n",
    "\n",
    "        # one basepair insertions\n",
    "        predonebpinsfreq = []\n",
    "        obsonebpinsfreq = []\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"]) \n",
    "            onebpins = [is_1bp_insertion(x, method) for x in indels]\n",
    "            predonebpinsratio = sum(np.array(data[t][method][target_site][\"predicted\"])[onebpins])/sum(data[t][method][target_site][\"predicted\"])\n",
    "            predonebpinsfreq.append(predonebpinsratio)\n",
    "            obsonebpinsratio = sum(np.array(data[t][method][target_site][\"actual\"])[onebpins])/sum(data[t][method][target_site][\"actual\"])\n",
    "            obsonebpinsfreq.append(obsonebpinsratio)\n",
    "        onebpinsmse = mean_squared_error(predonebpinsfreq, obsonebpinsfreq)\n",
    "\n",
    "        # one bp frameshift\n",
    "        predonebpframeshiftfreq = []\n",
    "        obsonebpframeshiftfreq = []\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"]) \n",
    "            onebpframeshift = [is_frameshift(x, method, 1) for x in indels]\n",
    "            predonebpframeshiftratio = sum(np.array(data[t][method][target_site][\"predicted\"])[onebpframeshift])/sum(data[t][method][target_site][\"predicted\"])\n",
    "            predonebpframeshiftfreq.append(predonebpframeshiftratio)\n",
    "            obsonebpframeshiftratio = sum(np.array(data[t][method][target_site][\"actual\"])[onebpframeshift])/sum(data[t][method][target_site][\"actual\"])\n",
    "            obsonebpframeshiftfreq.append(obsonebpframeshiftratio)\n",
    "        onebpframeshiftmse = mean_squared_error(predonebpframeshiftfreq, obsonebpframeshiftfreq)\n",
    "\n",
    "        # two bp frameshift\n",
    "        predtwobpframeshiftfreq = []\n",
    "        obstwobpframeshiftfreq = []\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"]) \n",
    "            twobpframeshift = [is_frameshift(x, method, 2) for x in indels]\n",
    "            predtwobpframeshiftratio = sum(np.array(data[t][method][target_site][\"predicted\"])[twobpframeshift])/sum(data[t][method][target_site][\"predicted\"])\n",
    "            predtwobpframeshiftfreq.append(predtwobpframeshiftratio)\n",
    "            obstwobpframeshiftratio = sum(np.array(data[t][method][target_site][\"actual\"])[twobpframeshift])/sum(data[t][method][target_site][\"actual\"])\n",
    "            obstwobpframeshiftfreq.append(obstwobpframeshiftratio)\n",
    "        twobpframeshiftmse = mean_squared_error(predtwobpframeshiftfreq, obstwobpframeshiftfreq)\n",
    "        \n",
    "        # frameshift\n",
    "        predframeshiftfreq = []\n",
    "        obsframeshiftfreq = []\n",
    "        for target_site in common_oligos[t]:\n",
    "            indels = np.array(data[t][method][target_site][\"indels\"]) \n",
    "            frameshift = [is_frameshift(x, method, \"any\") for x in indels]\n",
    "            predframeshiftratio = sum(np.array(data[t][method][target_site][\"predicted\"])[frameshift])/sum(data[t][method][target_site][\"predicted\"])\n",
    "            predframeshiftfreq.append(predframeshiftratio)\n",
    "            obsframeshiftratio = sum(np.array(data[t][method][target_site][\"actual\"])[frameshift])/sum(data[t][method][target_site][\"actual\"])\n",
    "            obsframeshiftfreq.append(obsframeshiftratio)\n",
    "        frameshiftmse = mean_squared_error(predframeshiftfreq, obsframeshiftfreq)\n",
    "\n",
    "\n",
    "        rows.append([delmse, onebpdelmse, onebpinsmse, onebpframeshiftmse, twobpframeshiftmse, frameshiftmse])\n",
    "        indices.append((test_f, method))\n",
    "  \n",
    "indices = pd.MultiIndex.from_tuples(indices, names=[\"Dataset\", \"Method\"])\n",
    "df = pd.DataFrame(rows, index=indices, columns=[\"Deletion\", \"1BP Deletion\", \"1BP Insertion\", \"1BP Frameshift\", \"2BP Frameshift\", \"Frameshift\"])\n",
    "df.groupby([\"Dataset\", \"Method\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CROTON comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROTON_F = \"/Users/colm/repos/output/local/model_predictions/CROTON/{}_new.pkl\"\n",
    "\n",
    "summ_data = {}\n",
    "\n",
    "for i, t in enumerate(TEST_FILES):\n",
    "    croton_d = pkl.load(open(CROTON_F.format(t), 'rb'))\n",
    "    summ_data[t] = croton_d\n",
    "\n",
    "croton_i = pd.MultiIndex.from_product([[file_mapping[t] for t in TEST_FILES], [\"CROTON\"]], names=[\"Dataset\", \"Method\"])\n",
    "\n",
    "\n",
    "croton_del_freq_mse = []\n",
    "croton_prob_1bpins_mse = []\n",
    "croton_prob_1bpdel_mse = []\n",
    "croton_one_bp_frameshift_mse = []\n",
    "croton_two_bp_frameshift_mse = []\n",
    "croton_frameshift_mse = []\n",
    "\n",
    "for t in TEST_FILES:\n",
    "    croton_del_freq_mse.append(mean_squared_error(summ_data[t][\"predicted\"][\"del_freq\"], summ_data[t][\"actual\"][\"del_freq\"]))\n",
    "    croton_prob_1bpins_mse.append(mean_squared_error(summ_data[t][\"predicted\"][\"prob_1bpins\"], summ_data[t][\"actual\"][\"prob_1bpins\"]))\n",
    "    croton_prob_1bpdel_mse.append(mean_squared_error(summ_data[t][\"predicted\"][\"prob_1bpdel\"], summ_data[t][\"actual\"][\"prob_1bpdel\"]))\n",
    "    croton_one_bp_frameshift_mse.append(mean_squared_error(summ_data[t][\"predicted\"][\"one_bp_frameshift\"], summ_data[t][\"actual\"][\"one_bp_frameshift\"]))\n",
    "    croton_two_bp_frameshift_mse.append(mean_squared_error(summ_data[t][\"predicted\"][\"two_bp_frameshift\"], summ_data[t][\"actual\"][\"two_bp_frameshift\"]))\n",
    "    croton_frameshift_mse.append(mean_squared_error(summ_data[t][\"predicted\"][\"frameshift\"], summ_data[t][\"actual\"][\"frameshift\"]))\n",
    "\n",
    "croton_mse_d = pd.DataFrame({\n",
    "    \"Deletion\": croton_del_freq_mse,\n",
    "    \"1BP Insertion\": croton_prob_1bpins_mse,\n",
    "    \"1BP Deletion\": croton_prob_1bpdel_mse,\n",
    "    \"1BP Frameshift\": croton_one_bp_frameshift_mse,\n",
    "    \"2BP Frameshift\": croton_two_bp_frameshift_mse,\n",
    "    \"Frameshift\": croton_frameshift_mse,\n",
    "}, index=croton_i)\n",
    "\n",
    "croton_mse_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, croton_mse_d]).sort_index()\n",
    "df.to_csv(\"/Users/colm/repos/x-crisp/data/processed/Performance/stats_comparison.tsv\", sep=\"\\t\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xcrisp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
